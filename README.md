# Домашнее задание к занятию "3.8. Компьютерные сети, лекция 3"

1. Почему висит InActConn. 
Почитал документ https://docs.huihoo.com/hpc-cluster/linux-virtual-server/HOWTO/LVS-HOWTO.ipvsadm.html 
В  режиме direct routing часть tcp сессии идет через директор, а часть через конечный сервер. В нашем примере NGINX. 
Директор не понимает состояния TCP сессии поэтому какое-то время пытается держать сессию в состоянии InActConn, время удержания сессии можно задавать в настройках. В NAT режиме директор бы видел всю сессию целиком.

2. Создана тестовая среда из 5 машин: 1 клиент client (192.168.10.10), 2 директора lb01 и lb02 (192.168.10.11 и 12), 2 NGINX сервера nginx01 и nginx02 (192.168.10.13 и 14).
vagrant файл src\vagrant
Конфигурация директоров в папках src\lb01 и src\lb02. Приведены конфигурации для настройки ipvsmadm и keepalived.
Конфигурации NGINX серверов в папках src\nginx01 и src\nginx02. Приведены конфигурации для настройки IP адресов для работы ipvsadm и необходимые для корректной работы параметры sysctl.
\
Решение проблемы проверки NGINX сервера. Вижу 2 простых решения: или с директоров по крону проверять доступность сервиса и включать или исключать нужный NGINX сервер из ipvs, или на NGINX серверах поднять дополнительные VIP адреса с проверками доступности сервиса NGINX и завязать ipvs на них. VIP адреса NGINX серверов, по неактивности, будут переезжать на другие NGINX сервера в VRRP кластере. 
Пошел по пути keepalived. Конфигурация лежит src\nginx01\etc\keepalived и src\nginx02\etc\keepalived

3. Самое простое - повесить 2 VIP адреса на эти машины. Но нет никакой гарантии, что при выключении случайной машины эти 2 IP адреса не окажутся на одной машине. Что приведет к перегрузке интерфейса. 
Поэтому, лучше всего сделать 3 VIP адреса по одному накаждую машину. Тогда при отключении любой машины проучится гарантировать, что на оставшихся машинах будет минимум по одному IP адресу.
